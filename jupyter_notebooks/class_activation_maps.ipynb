{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02534c05",
   "metadata": {},
   "source": [
    "Purpose of this notebook is to plot the Class Activation Maps for the different emotion-classes in the dataset. CAMs further visualize where the model detects salient emotion-specific features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2e80c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfd7457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('PATH_TO_FEC_MODEL_FILE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a0764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.fer_models import FEClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe87b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = FEClassifier(base='efficientnet')\n",
    "model.load_state_dict(torch.load(\"/content/effnetb2_14_2.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45fe7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.load('/content/test_loader.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51449b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09efe53",
   "metadata": {},
   "source": [
    "Samples can be chosen from each class specifically or from the entirety of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af76e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'anger': 2557, 'disgust': 418, 'fear': 685, 'happy': 13570, 'neutral': 7587, 'sad': 2486, 'surprise': 1438}\n",
    "# angry = test_loader.dataset[random.randint(0,2557)]\n",
    "# disgust = test_loader.dataset[random.randint(2558,2976)]\n",
    "# fear = test_loader.dataset[random.randint(2977,3662)]\n",
    "# happy = test_loader.dataset[random.randint(3663,17233)]\n",
    "# neutral = test_loader.dataset[random.randint(17234,24821)]\n",
    "# sad = test_loader.dataset[random.randint(24822,27308)]\n",
    "# surprise = test_loader.dataset[random.randint(27309,28747)]\n",
    "# datasample = [angry,disgust,fear,happy,neutral,sad,surprise]\n",
    "datasample = [test_loader.dataset[random.randint(27309,28747)] for _ in range(5)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2377c9b",
   "metadata": {},
   "source": [
    "CAMs are extracted according to source code from https://github.com/frgfm/torch-cam/tree/main?tab=readme-ov-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee97938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchcam.methods import SmoothGradCAMpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbba53d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cams,pred_labels = [],[]\n",
    "for data in datasample:\n",
    "  with SmoothGradCAMpp(model) as cam_extractor:\n",
    "      image = data[0]\n",
    "      logits = model(image.unsqueeze(0))\n",
    "      pred_label = torch.argmax(logits,dim=1)\n",
    "      pred_labels.append(pred_label.item())\n",
    "      activation_map = cam_extractor(pred_label.item(),logits)\n",
    "      cams.append(activation_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c663245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchcam.utils import overlay_mask\n",
    "from torchvision.transforms.v2.functional import to_pil_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbbd21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {0: 'anger',1:'disgust',2:'fear',3:'happy',4:'neutral' ,5:'sad',6:'surprise'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e16ae0",
   "metadata": {},
   "source": [
    "Images need to be unnormalized before plotting because they were loaded from a pth file containing a test set of normalized images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50427cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223bdd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor([0.5474, 0.4259, 0.3695]) tensor([0.2782, 0.2465, 0.2398])\n",
    "#tensor([0.5691, 0.4458, 0.3910]) tensor([0.2746, 0.2446, 0.2383]) for only affectnet, no gen images\n",
    "unnorm = UnNormalize(mean=(0.5691, 0.4458, 0.3910),std=(0.2746, 0.2446, 0.2383))\n",
    "for image,label in datasample:\n",
    "  image = unnorm(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ac1f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,5,figsize=(16,4))\n",
    "for i,(data,cam) in enumerate(zip(datasample,cams)):\n",
    "  result = overlay_mask(to_pil_image(data[0],mode='RGB'),to_pil_image(cam[0],mode='F'),alpha=0.5)\n",
    "  plt.subplot(1,5,i+1)\n",
    "  plt.title(f\"Predicted label: {class_names[pred_labels[i]]}\\nTrue Label: {class_names[data[1]]}\",\n",
    "            fontsize=8)\n",
    "  plt.imshow(result)\n",
    "  plt.axis('off')\n",
    "  plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
